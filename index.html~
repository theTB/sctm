<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="SCTM : Specific Correspondence Topic Model">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>SCTM</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
		<a id="home_banner" href="theTB.github.io">Home</a> 
		<a id="forkme_banner" href="https://github.com/theTB/sctm">View on GitHub</a>
        <header class="inner">
          <h1 id="project_title">SCTM</h1>
          <h2 id="project_tagline">Specific Correspondence Topic Model</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/theTB/sctm/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/theTB/sctm/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="specific-correspondence-topic-model" class="anchor" href="#specific-correspondence-topic-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Specific Correspondence Topic Model</h1>

<p>Code for the paper:<br>
<em>"<a href="http://dl.acm.org/citation.cfm?id=2556231">Going Beyond Corr-LDA for Detecting Specific Comments on News &amp; Blogs</a>". In ACM international conference on Web Search and Data Mining (WSDM), 2014.</em></p>

<hr>

<p>This implementation contains the following 3 models:  </p>

<ol>
<li><p><em>Latent Dirichlet Allocation</em> (LDA)<br>
Basic LDA model with collapsed Gibbs sampling. A bonus feature included is <em>sparse topics</em> which allows learning sparse topic distributions which are more diverse on their set of top words (see paper for details).</p></li>
<li><p><em>Correspondence LDA</em> (CorrLDA)<br>
CorrLDA model for articles and comments (or any two paired sets of documents). The latent topic space is shared between the articles and comments. As an improvement over vanilla model, this also includes an <em>irrelevant topic</em> for comments (see paper) and the feature of <em>sparse topics</em>. Inference is collapsed Gibbs sampling.</p></li>
<li><p><em>Specific Correspondence Topic Model</em> (SCTM)<br>
This is the model proposed in the paper for modeling specific correspondence between articles and comments. Includes the features of <em>irrelevant topic</em> and <em>sparse topics</em>. Implements <em>multiple topic vectors</em> and <em>specific correspondence</em> (see paper for details).</p></li>
</ol>

<h4>
<a id="using-the-code" class="anchor" href="#using-the-code" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using the Code</h4>

<p>Download all the code files and go into the folder called "<em>Release</em>". This contains the Makefile. Compile the code,  <code>make clean; make</code>. The main exectuable is called "<em>sctm</em>".  </p>

<p>Usage : <code>./sctm &lt;1.article-file&gt; &lt;2.comments-file&gt; &lt;3.output-dir&gt; &lt;4.topics&gt; &lt;5.model&gt; &lt;6.train/test&gt;</code><br>
where</p>

<ul>
<li>
<em>article-file</em> is the location of the file containing the article contents</li>
<li>
<em>comments-file</em> is the location of the file containing the comment contents (ignored for <em>lda</em> model)</li>
<li>
<em>output-dir</em> is the location and name of the directory to write output</li>
<li>
<em>topics</em> is the number of topics (K)</li>
<li>
<em>model</em> is the model to train, one of: <em>lda</em>, <em>corrlda</em>, <em>sctm</em>
</li>
<li>
<em>train/test</em> (optional), 1 for test data (in this case output-dir should point to location of trained model)</li>
</ul>

<p>There is a sample pre-processed dataset of 501 documents and some comments provided in the folder "<em>input</em>". To run a demo on this dataset with 100 topics, use the command:<br>
<code>./sctm ../input/abagf.AT.txt ../input/cbagf.AT.txt ../output 100 sctm</code></p>

<h4>
<a id="input-data-format" class="anchor" href="#input-data-format" aria-hidden="true"><span class="octicon octicon-link"></span></a>Input Data Format</h4>

<p>All words should be converted to integer vocabulary ids' starting from 0.  </p>

<ul>
<li><p>Article Format<br>
The first line contains the number of documents D. Each document begins with the number of sentences in first line S. Each of the S lines begin with the number of words in the sentence (N), followed by each word id.
Example:<br>
2<br>
S<sub>1</sub><br>
N<sub>1</sub> w<sub>1</sub> w<sub>2</sub> .... w<sub>N<sub>1</sub></sub><br>
S<sub>2</sub><br>
N<sub>2</sub> w<sub>1</sub> w<sub>2</sub> .... w<sub>N<sub>2</sub></sub>  </p></li>
<li><p>Comments Format<br>
Similar to above. First line is D. For each document, first line is number of comments C, followed by C lines with each line beginning with number of comment words N, followed by each comment word. Note that if there is a document with no comments, it should be present in the file with 0 (for C) and no following lines.</p></li>
</ul>

<h4>
<a id="output" class="anchor" href="#output" aria-hidden="true"><span class="octicon octicon-link"></span></a>Output</h4>

<p>Following are the four outputs from the model:</p>

<ul>
<li>
<em>Topic distributions</em>: The learned topics by the model. The last topic is always the <em>irrelevant topic</em>. So if the model is run with K topics, then K+1 topics are output. The last topic should be ignored for LDA model. File "<em>beta</em>".<br>
</li>
<li>
<em>Comment topic distribution</em>: Topic distribution (over K+1 topics) of each comment. File "<em>y_dist.txt</em> ".<br>
</li>
<li>
<em>Article topic distribution</em>: Overall topic distribution (over K topics) of each article. File "<em>z_dist.txt</em> ".<br>
</li>
<li>
<em>Sentence selection probability</em>: The probability of correspondence of a comment to each article sentence (see paper). File "<em>xi_prob.txt</em>".<br>
</li>
</ul>

<p>The dot products of the article and comment topic distributions are used for the applications described in the paper.</p>

<h4>
<a id="querieshelp" class="anchor" href="#querieshelp" aria-hidden="true"><span class="octicon octicon-link"></span></a>Queries/Help</h4>

<p>Direct any queries to "trapitbansal at gmail dot com".</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">SCTM maintained by <a href="https://github.com/theTB">theTB</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
